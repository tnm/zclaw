# zedclaw configuration - copy to .env and fill in your values
# .env is loaded automatically from the current directory

# ── LLM Backend ──────────────────────────────────────────────────────────────
# Options: anthropic | openai | openrouter | ollama
ZEDCLAW_LLM_BACKEND=anthropic

# API key for the selected backend (not needed for Ollama)
ZEDCLAW_LLM_API_KEY=sk-ant-your-key-here

# Optional: override model (default varies by backend)
# ZEDCLAW_LLM_MODEL=claude-opus-4-5
# ZEDCLAW_LLM_MODEL=gpt-4o
# ZEDCLAW_LLM_MODEL=qwen3:8b

# Optional: override API endpoint (useful for Ollama or self-hosted)
# ZEDCLAW_LLM_API_URL=http://host.docker.internal:11434/v1/chat/completions
# ZEDCLAW_LLM_API_URL=http://localhost:11434/v1/chat/completions

# ── OpenAI ────────────────────────────────────────────────────────────────────
# ZEDCLAW_LLM_BACKEND=openai
# ZEDCLAW_LLM_API_KEY=sk-your-openai-key

# ── OpenRouter ────────────────────────────────────────────────────────────────
# ZEDCLAW_LLM_BACKEND=openrouter
# ZEDCLAW_LLM_API_KEY=sk-or-your-openrouter-key
# ZEDCLAW_LLM_MODEL=anthropic/claude-opus-4-5

# ── Ollama (local) ────────────────────────────────────────────────────────────
# ZEDCLAW_LLM_BACKEND=ollama
# ZEDCLAW_LLM_API_URL=http://localhost:11434/v1/chat/completions
# ZEDCLAW_LLM_MODEL=qwen3:8b
# (no API key needed for Ollama)

# ── Telegram Bot (optional) ──────────────────────────────────────────────────
# Get a token from @BotFather on Telegram
# ZEDCLAW_TELEGRAM_TOKEN=1234567890:ABCdef...

# ── Storage ──────────────────────────────────────────────────────────────────
# Where to store memories, cron jobs, and user tools
# Defaults to ~/.config/zedclaw (or /data when running in container)
# ZEDCLAW_DATA_DIR=/path/to/data

# ── Timezone ─────────────────────────────────────────────────────────────────
# Used for daily cron schedules and get_time tool
# ZEDCLAW_TIMEZONE=UTC
# ZEDCLAW_TIMEZONE=America/New_York
# ZEDCLAW_TIMEZONE=America/Los_Angeles
